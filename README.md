# VFX Orchestrator // The Testing Rig

**Technical Proof of Concept**: Intent-Based Workflow Validation

## Overview

This Jupyter Notebook serves as a portable Testing Rig for architecting and validating high-fidelity AI video workflows. While my private library contains proprietary "Golden Seed" manifests, this sandbox environment demonstrates the Orchestration Layer logic used to translate natural language "vibes" into cinema-grade GPU directives.

The Goal: To move beyond hard-coded node paths by training an Agent to map user intent to physical technical specifications.

### The Methodology: Visual Unit Testing
In high-end generative pipelines, traditional software testing is insufficient. I have implemented a "Vibe-Check" protocol:

Execution: The Agent synthesises a JSON workflow (ComfyUI API format).

Validation: The rig facilitates the physical reconstruction of the graph to audit for temporal stability and physical realism.

Evaluation: Only workflows that pass these high-precision audits are codified into the permanent instruction set.

### Technical Architecture
Orchestrator Agent: A middleware layer that bridges the gap between raw GPU compute and natural language requirements.

Intent Mapping: Automated translation of aesthetic cues (e.g., "Anamorphic Bokeh", "Volumetric Light") into specific model endpoints and node configurations.

Pattern Recognition: Identifies "Anchor Nodes" (e.g., IP-Adapter for identity lock) to ensure consistency across complex multi-subject scenes.

### Usage
Users can run this notebook to simulate the "Crowd" Stress Testâ€”analysing how the system manages 17 distinct layers of intent to maintain pro-realism in high-density visual environments.
